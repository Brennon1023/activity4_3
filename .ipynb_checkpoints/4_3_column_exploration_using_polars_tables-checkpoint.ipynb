{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70db985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from glob import glob\n",
    "from toolz import pipe\n",
    "from functools import reduce\n",
    "from operator import add, mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49898a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./data/uber/uber-bad.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Remove the bad file (See below)\n",
    "!rm ./data/uber/uber-bad.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19344bae",
   "metadata": {},
   "source": [
    "# Column exploration using `polars` tables.\n",
    "\n",
    "In this lecture, we will explore how to use `polars` tables to explore the columns across many files. This will help us find and fix problems with the naming and order of columns across the files.\n",
    "\n",
    "**Basic procedure:** We want to make a column summary table that shows which columns are present in each file. We will do this by:\n",
    "1. Use `glob` to find all files matching a pattern.\n",
    "1. Read in each file as a list of `polars` tables.\n",
    "2. Stack all columns and aggregate to find unique columns and their counts.\n",
    "3. Create an columns containing the literal value of `1`.\n",
    "4. Use a reduction to join all the tables together on the column names.\n",
    "5. Replace missing values with `0`.\n",
    "6. Explore the resulting table to find problems, e.g. columns that are not in all files, columns with different capitalization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff88820",
   "metadata": {},
   "source": [
    "### Example - Exploring the columns in Uber data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4073b1",
   "metadata": {},
   "source": [
    "#### Step 1: Use `glob` to find all files matching a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6de905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/uber/uber-raw-data-jun14-sample.csv',\n",
       " './data/uber/uber-raw-data-apr14-sample.csv',\n",
       " './data/uber/uber-raw-data-may14-sample.csv',\n",
       " './data/uber/uber-raw-data-sep14-sample.csv',\n",
       " './data/uber/uber-raw-data-aug14-sample.csv',\n",
       " './data/uber/uber-raw-data-jul14-sample.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_paths :=\n",
    " glob('./data/uber/*.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebcaa5",
   "metadata": {},
   "source": [
    "#### Step 2: Read and process each file\n",
    "\n",
    "**Procedure:**\n",
    "1. Read one row from each file.\n",
    "2. Add a new column containing the file name.\n",
    "3. Use `unpivot` to stack all columns except the file name.\n",
    "4. Drop the values column.\n",
    "5. Add a new column containing the literal value of `1`.\n",
    "6. Use `pivot` to unstack the table so that each file is a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478791d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/7ykd2jqx0_bb8s6ybyq242480000gn/T/ipykernel_22799/2348454989.py:8: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.\n",
      "  .pivot(index = 'Column', columns='file', values='ones')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-jun14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘,\n",
       " shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-apr14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘,\n",
       " shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-may14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘,\n",
       " shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-sep14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘,\n",
       " shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-aug14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘,\n",
       " shape: (4, 2)\n",
       " ┌───────────┬────────────────────────────────┐\n",
       " │ Column    ┆ uber-raw-data-jul14-sample.csv │\n",
       " │ ---       ┆ ---                            │\n",
       " │ str       ┆ i32                            │\n",
       " ╞═══════════╪════════════════════════════════╡\n",
       " │ Date/Time ┆ 1                              │\n",
       " │ Lat       ┆ 1                              │\n",
       " │ Lon       ┆ 1                              │\n",
       " │ Base      ┆ 1                              │\n",
       " └───────────┴────────────────────────────────┘]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_tables :=\n",
    " [pl.read_csv(p)\n",
    "    .head(1)\n",
    "     .with_columns(file = pl.lit(p.replace('\\\\','/').split('/')[-1]))\n",
    "     .unpivot(index='file', variable_name='Column')\n",
    "     .drop('value')\n",
    "     .with_columns(pl.lit(1).alias('ones'))\n",
    "     .pivot(index = 'Column', columns='file', values='ones')\n",
    "  for p in uber_paths\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500a5a2",
   "metadata": {},
   "source": [
    "#### Step 3: Combine all the processed tables into a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe90784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pl.DataFrame({'Column': ['a', 'b'],\n",
    "                    'file1.csv':2*[1]})\n",
    "df2 = pl.DataFrame({'Column': ['a', 'c'],\n",
    "                    'file2.csv':2*[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd9d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/7ykd2jqx0_bb8s6ybyq242480000gn/T/ipykernel_22799/297218877.py:1: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  (df1.join(df2,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>file1.csv</th><th>file2.csv</th></tr><tr><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;a&quot;</td><td>1</td><td>1</td></tr><tr><td>&quot;c&quot;</td><td>null</td><td>1</td></tr><tr><td>&quot;b&quot;</td><td>1</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────┬───────────┬───────────┐\n",
       "│ Column ┆ file1.csv ┆ file2.csv │\n",
       "│ ---    ┆ ---       ┆ ---       │\n",
       "│ str    ┆ i64       ┆ i64       │\n",
       "╞════════╪═══════════╪═══════════╡\n",
       "│ a      ┆ 1         ┆ 1         │\n",
       "│ c      ┆ null      ┆ 1         │\n",
       "│ b      ┆ 1         ┆ null      │\n",
       "└────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df1.join(df2, \n",
    "          on='Column', \n",
    "          how = 'outer', \n",
    "          suffix = '_right',\n",
    "          )\n",
    "    .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "    .drop('Column_right')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e10b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/7ykd2jqx0_bb8s6ybyq242480000gn/T/ipykernel_22799/3979226099.py:1: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  join_next = lambda df1, df2: (df1.join(df2,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Base&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>&quot;Date/Time&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>&quot;Lat&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>&quot;Lon&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 7)\n",
       "┌───────────┬──────────────┬──────────────┬──────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ Column    ┆ uber-raw-dat ┆ uber-raw-dat ┆ uber-raw-dat ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da │\n",
       "│ ---       ┆ a-jun14-samp ┆ a-apr14-samp ┆ a-may14-samp ┆ ta-sep14-sa ┆ ta-aug14-sa ┆ ta-jul14-sa │\n",
       "│ str       ┆ le.csv       ┆ le.csv       ┆ le.csv       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    │\n",
       "│           ┆ ---          ┆ ---          ┆ ---          ┆ ---         ┆ ---         ┆ ---         │\n",
       "│           ┆ i32          ┆ i32          ┆ i32          ┆ i32         ┆ i32         ┆ i32         │\n",
       "╞═══════════╪══════════════╪══════════════╪══════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ Base      ┆ 1            ┆ 1            ┆ 1            ┆ 1           ┆ 1           ┆ 1           │\n",
       "│ Date/Time ┆ 1            ┆ 1            ┆ 1            ┆ 1           ┆ 1           ┆ 1           │\n",
       "│ Lat       ┆ 1            ┆ 1            ┆ 1            ┆ 1           ┆ 1           ┆ 1           │\n",
       "│ Lon       ┆ 1            ┆ 1            ┆ 1            ┆ 1           ┆ 1           ┆ 1           │\n",
       "└───────────┴──────────────┴──────────────┴──────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_next = lambda df1, df2: (df1.join(df2, \n",
    "                                       on='Column', \n",
    "                                       how = 'outer', \n",
    "                                       suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "(combined_tables :=\n",
    " reduce(join_next, uber_tables)\n",
    " .fill_null(0)\n",
    " .sort('Column') # Should help find similar names/spellings/cases\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b901de",
   "metadata": {},
   "source": [
    "#### Step 5: Explore the combined table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5247baca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Base&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Date/Time&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Lat&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Lon&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 9)\n",
       "┌───────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────┬───────┐\n",
       "│ Column    ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-d ┆ all ┆ count │\n",
       "│ ---       ┆ ta-jun14-sa ┆ ta-apr14-sa ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ata-jul14- ┆ --- ┆ ---   │\n",
       "│ str       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    ┆   ┆ mple.csv    ┆ sample.csv ┆ i32 ┆ i32   │\n",
       "│           ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---         ┆ ---        ┆     ┆       │\n",
       "│           ┆ i32         ┆ i32         ┆ i32         ┆   ┆ i32         ┆ i32        ┆     ┆       │\n",
       "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════╪═══════╡\n",
       "│ Base      ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Date/Time ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Lat       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Lon       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "└───────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(combined_tables :=\n",
    " combined_tables\n",
    " .with_columns(all = pl.reduce(mul, cs.starts_with('uber')),       # Multiple 1/0 columns <==> AND\n",
    "               count = pl.reduce(add, cs.starts_with('uber')),\n",
    "               )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f414837",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83be61d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;Base&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Date/Time&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Lat&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr><tr><td>&quot;Lon&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 9)\n",
       "┌───────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────┬───────┐\n",
       "│ Column    ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-d ┆ all ┆ count │\n",
       "│ ---       ┆ ta-jun14-sa ┆ ta-apr14-sa ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ata-jul14- ┆ --- ┆ ---   │\n",
       "│ str       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    ┆   ┆ mple.csv    ┆ sample.csv ┆ i32 ┆ i32   │\n",
       "│           ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---         ┆ ---        ┆     ┆       │\n",
       "│           ┆ i32         ┆ i32         ┆ i32         ┆   ┆ i32         ┆ i32        ┆     ┆       │\n",
       "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════╪═══════╡\n",
       "│ Base      ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Date/Time ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Lat       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "│ Lon       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 1   ┆ 6     │\n",
       "└───────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_next = lambda df1, df2: (df1.join(df2, on='Column', how = 'full', suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "\n",
    "(uber_column_summary :=\n",
    " pipe(glob('./data/uber/*.csv'),\n",
    "     lambda L: [pl.read_csv(p)\n",
    "                  .with_columns(file = pl.lit(p.replace('\\\\','/').split('/')[-1]))\n",
    "                  .head(1) \n",
    "                  .unpivot(index='file', \n",
    "                           variable_name='Column')\n",
    "                  .drop('value')\n",
    "                  .with_columns(pl.lit(1).alias('ones'))\n",
    "                  .pivot(index = 'Column', \n",
    "                         on='file', \n",
    "                         values='ones') \n",
    "                for p in L \n",
    "                ],\n",
    "     lambda L: reduce(join_next, L).sort('Column').fill_null(0),\n",
    "     lambda df: df.with_columns(all = pl.reduce(mul, cs.starts_with('uber')), \n",
    "                                count = pl.reduce(add, cs.starts_with('uber'))\n",
    "                               ),\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bfaa1",
   "metadata": {},
   "source": [
    "#### Look for missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d38bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 9)\n",
       "┌────────┬──────────────┬──────────────┬─────────────┬───┬─────────────┬─────────────┬─────┬───────┐\n",
       "│ Column ┆ uber-raw-dat ┆ uber-raw-dat ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-da ┆ all ┆ count │\n",
       "│ ---    ┆ a-jun14-samp ┆ a-apr14-samp ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ta-jul14-sa ┆ --- ┆ ---   │\n",
       "│ str    ┆ le.csv       ┆ le.csv       ┆ mple.csv    ┆   ┆ mple.csv    ┆ mple.csv    ┆ i32 ┆ i32   │\n",
       "│        ┆ ---          ┆ ---          ┆ ---         ┆   ┆ ---         ┆ ---         ┆     ┆       │\n",
       "│        ┆ i32          ┆ i32          ┆ i32         ┆   ┆ i32         ┆ i32         ┆     ┆       │\n",
       "╞════════╪══════════════╪══════════════╪═════════════╪═══╪═════════════╪═════════════╪═════╪═══════╡\n",
       "└────────┴──────────────┴──────────────┴─────────────┴───┴─────────────┴─────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_column_summary\n",
    " .filter(pl.col('all') == 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b627e01",
   "metadata": {},
   "source": [
    "#### Find columns that are not in all files with a count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f3ab273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 9)\n",
       "┌────────┬──────────────┬──────────────┬─────────────┬───┬─────────────┬─────────────┬─────┬───────┐\n",
       "│ Column ┆ uber-raw-dat ┆ uber-raw-dat ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-da ┆ all ┆ count │\n",
       "│ ---    ┆ a-jun14-samp ┆ a-apr14-samp ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ta-jul14-sa ┆ --- ┆ ---   │\n",
       "│ str    ┆ le.csv       ┆ le.csv       ┆ mple.csv    ┆   ┆ mple.csv    ┆ mple.csv    ┆ i32 ┆ i32   │\n",
       "│        ┆ ---          ┆ ---          ┆ ---         ┆   ┆ ---         ┆ ---         ┆     ┆       │\n",
       "│        ┆ i32          ┆ i32          ┆ i32         ┆   ┆ i32         ┆ i32         ┆     ┆       │\n",
       "╞════════╪══════════════╪══════════════╪═════════════╪═══╪═════════════╪═════════════╪═════╪═══════╡\n",
       "└────────┴──────────────┴──────────────┴─────────────┴───┴─────────────┴─────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_column_summary\n",
    " .filter(pl.col('count') != pl.col('count').max())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a318e",
   "metadata": {},
   "source": [
    "## What if things go wrong?\n",
    "\n",
    "Now let's manufacture some problems with the files and see how we can use our column exploration table to find and fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516f1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uber_paths[0] \n",
    "original_columns = (pl.read_csv(f).head(1).columns)\n",
    "\n",
    "(pl.read_csv(f)\n",
    "   .rename({c:c.upper() for c in original_columns})\n",
    "   .write_csv(f'data/uber/uber-bad.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b7329",
   "metadata": {},
   "source": [
    "#### Redo the column summary table to see what has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2451cc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-bad.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;BASE&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Base&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;DATE/TIME&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Date/Time&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;LAT&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;LON&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Lat&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;Lon&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 10)\n",
       "┌───────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────┬───────┐\n",
       "│ Column    ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-d ┆ all ┆ count │\n",
       "│ ---       ┆ ta-jun14-sa ┆ ta-apr14-sa ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ata-jul14- ┆ --- ┆ ---   │\n",
       "│ str       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    ┆   ┆ mple.csv    ┆ sample.csv ┆ i32 ┆ i32   │\n",
       "│           ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---         ┆ ---        ┆     ┆       │\n",
       "│           ┆ i32         ┆ i32         ┆ i32         ┆   ┆ i32         ┆ i32        ┆     ┆       │\n",
       "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════╪═══════╡\n",
       "│ BASE      ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Base      ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ DATE/TIME ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Date/Time ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ LAT       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ LON       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Lat       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ Lon       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "└───────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_next = lambda df1, df2: (df1.join(df2, on='Column', how = 'full', suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "\n",
    "(uber_column_summary :=\n",
    " pipe(glob('./data/uber/*.csv'),\n",
    "     lambda L: [pl.read_csv(p)\n",
    "                  .with_columns(file = pl.lit(p.split('/')[-1]))\n",
    "                  .head(1) \n",
    "                  .unpivot(index='file', \n",
    "                           variable_name='Column')\n",
    "                  .drop('value')\n",
    "                  .with_columns(pl.lit(1).alias('ones'))\n",
    "                  .pivot(index = 'Column', \n",
    "                         on='file', \n",
    "                         values='ones') \n",
    "                for p in L \n",
    "                ],\n",
    "     lambda L: reduce(join_next, L).sort('Column').fill_null(0),\n",
    "     lambda df: df.with_columns(all = pl.reduce(mul, cs.starts_with('uber')), \n",
    "                                count = pl.reduce(add, cs.starts_with('uber'))\n",
    "                               ),\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b29325",
   "metadata": {},
   "source": [
    "#### Look for missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3672f752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-bad.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;BASE&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Base&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;DATE/TIME&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Date/Time&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;LAT&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;LON&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;Lat&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr><tr><td>&quot;Lon&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 10)\n",
       "┌───────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────┬───────┐\n",
       "│ Column    ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-d ┆ all ┆ count │\n",
       "│ ---       ┆ ta-jun14-sa ┆ ta-apr14-sa ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ata-jul14- ┆ --- ┆ ---   │\n",
       "│ str       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    ┆   ┆ mple.csv    ┆ sample.csv ┆ i32 ┆ i32   │\n",
       "│           ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---         ┆ ---        ┆     ┆       │\n",
       "│           ┆ i32         ┆ i32         ┆ i32         ┆   ┆ i32         ┆ i32        ┆     ┆       │\n",
       "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════╪═══════╡\n",
       "│ BASE      ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Base      ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ DATE/TIME ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Date/Time ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ LAT       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ LON       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ Lat       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "│ Lon       ┆ 1           ┆ 1           ┆ 1           ┆ … ┆ 1           ┆ 1          ┆ 0   ┆ 6     │\n",
       "└───────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_column_summary\n",
    " .filter(pl.col('all') == 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470bf3f",
   "metadata": {},
   "source": [
    "#### Find columns that are not in all files with a count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5916ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>uber-raw-data-jun14-sample.csv</th><th>uber-raw-data-apr14-sample.csv</th><th>uber-raw-data-may14-sample.csv</th><th>uber-raw-data-sep14-sample.csv</th><th>uber-bad.csv</th><th>uber-raw-data-aug14-sample.csv</th><th>uber-raw-data-jul14-sample.csv</th><th>all</th><th>count</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;BASE&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;DATE/TIME&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;LAT&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;LON&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 10)\n",
       "┌───────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬────────────┬─────┬───────┐\n",
       "│ Column    ┆ uber-raw-da ┆ uber-raw-da ┆ uber-raw-da ┆ … ┆ uber-raw-da ┆ uber-raw-d ┆ all ┆ count │\n",
       "│ ---       ┆ ta-jun14-sa ┆ ta-apr14-sa ┆ ta-may14-sa ┆   ┆ ta-aug14-sa ┆ ata-jul14- ┆ --- ┆ ---   │\n",
       "│ str       ┆ mple.csv    ┆ mple.csv    ┆ mple.csv    ┆   ┆ mple.csv    ┆ sample.csv ┆ i32 ┆ i32   │\n",
       "│           ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---         ┆ ---        ┆     ┆       │\n",
       "│           ┆ i32         ┆ i32         ┆ i32         ┆   ┆ i32         ┆ i32        ┆     ┆       │\n",
       "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪════════════╪═════╪═══════╡\n",
       "│ BASE      ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ DATE/TIME ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ LAT       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "│ LON       ┆ 0           ┆ 0           ┆ 0           ┆ … ┆ 0           ┆ 0          ┆ 0   ┆ 1     │\n",
       "└───────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴────────────┴─────┴───────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_column_summary\n",
    " .filter(pl.col('count') != pl.col('count').max())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b6be0",
   "metadata": {},
   "source": [
    "## Fixing problems\n",
    "\n",
    "**Basic procedure:** To fix problems with column names, we will:\n",
    "1. Read all original columns into a dict of dict.  The outer dict will have a key mapping to the file name and a value mapping to a dict of column names for that file.  The inner dict will have a key mapping to the original column name and a value mapping to the original column name.  \n",
    "2. These inner dict are meant to be used to rename columns.  We will use a function to apply the following transformations:\n",
    "   - Renaming columns\n",
    "   - Changing the case of columns\n",
    "3. Additionally, we may need use `select` to reorder columns and add/remove missing columns.\n",
    "   - Reordering columns\n",
    "   - Adding/removing missing columns\n",
    "   - Recasting columns to a specific data type\n",
    "  \n",
    "\n",
    "**Note.** This is a manual process that requires knowledge of the data and the desired column names and order, so solutions will vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cb5e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/uber/uber-raw-data-jun14-sample.csv',\n",
       " './data/uber/uber-raw-data-apr14-sample.csv',\n",
       " './data/uber/uber-raw-data-may14-sample.csv',\n",
       " './data/uber/uber-raw-data-sep14-sample.csv',\n",
       " './data/uber/uber-bad.csv',\n",
       " './data/uber/uber-raw-data-aug14-sample.csv',\n",
       " './data/uber/uber-raw-data-jul14-sample.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_paths :=\n",
    " glob('./data/uber/*.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f3adc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./data/uber/uber-raw-data-jun14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-apr14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-may14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-sep14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-bad.csv': {'DATE/TIME': 'DATE/TIME',\n",
       "  'LAT': 'LAT',\n",
       "  'LON': 'LON',\n",
       "  'BASE': 'BASE'},\n",
       " './data/uber/uber-raw-data-aug14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-jul14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(original_columns :=\n",
    " {p:{col: col\n",
    "     for col in \n",
    "     pl.read_csv(p).columns\n",
    "    }\n",
    "  for p in uber_paths\n",
    " }\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7be386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./data/uber/uber-raw-data-jun14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-apr14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-may14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-sep14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-bad.csv': {'DATE/TIME': 'Date/Time',\n",
       "  'LAT': 'Lat',\n",
       "  'LON': 'Lon',\n",
       "  'BASE': 'Base'},\n",
       " './data/uber/uber-raw-data-aug14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'},\n",
       " './data/uber/uber-raw-data-jul14-sample.csv': {'Date/Time': 'Date/Time',\n",
       "  'Lat': 'Lat',\n",
       "  'Lon': 'Lon',\n",
       "  'Base': 'Base'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fixed_columns :=\n",
    " {**original_columns, \n",
    "  './data/uber/uber-bad.csv':{col:col.title() \n",
    "                             for col in original_columns['./data/uber/uber-bad.csv']\n",
    "                             },\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af3a4f",
   "metadata": {},
   "source": [
    "#### Make a type and order specification for the correct columns (Brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b4e8ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date/Time': String, 'Lat': Float64, 'Lon': Float64, 'Base': String}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(col_and_types := {'Date/Time': pl.String(),\n",
    "                   'Lat': pl.Float64(),\n",
    "                   'Lon': pl.Float64(),\n",
    "                   'Base': pl.String(),\n",
    "                  }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e75b1",
   "metadata": {},
   "source": [
    "#### Make a type and order specification (programmatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a406b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date/Time</th><th>Lat</th><th>Lon</th><th>Base</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;6/19/2014 16:49:00&quot;</td><td>40.7568</td><td>-73.9701</td><td>&quot;B02682&quot;</td></tr><tr><td>&quot;6/12/2014 21:25:00&quot;</td><td>40.6463</td><td>-73.7768</td><td>&quot;B02598&quot;</td></tr><tr><td>&quot;6/15/2014 22:23:00&quot;</td><td>40.7205</td><td>-73.9575</td><td>&quot;B02512&quot;</td></tr><tr><td>&quot;6/14/2014 20:34:00&quot;</td><td>40.7639</td><td>-73.9624</td><td>&quot;B02617&quot;</td></tr><tr><td>&quot;6/13/2014 14:36:00&quot;</td><td>40.7665</td><td>-73.9667</td><td>&quot;B02598&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────────────┬─────────┬──────────┬────────┐\n",
       "│ Date/Time          ┆ Lat     ┆ Lon      ┆ Base   │\n",
       "│ ---                ┆ ---     ┆ ---      ┆ ---    │\n",
       "│ str                ┆ f64     ┆ f64      ┆ str    │\n",
       "╞════════════════════╪═════════╪══════════╪════════╡\n",
       "│ 6/19/2014 16:49:00 ┆ 40.7568 ┆ -73.9701 ┆ B02682 │\n",
       "│ 6/12/2014 21:25:00 ┆ 40.6463 ┆ -73.7768 ┆ B02598 │\n",
       "│ 6/15/2014 22:23:00 ┆ 40.7205 ┆ -73.9575 ┆ B02512 │\n",
       "│ 6/14/2014 20:34:00 ┆ 40.7639 ┆ -73.9624 ┆ B02617 │\n",
       "│ 6/13/2014 14:36:00 ┆ 40.7665 ┆ -73.9667 ┆ B02598 │\n",
       "└────────────────────┴─────────┴──────────┴────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_correct_table := pl.read_csv(uber_paths[0]).head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40301bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date/Time', 'Base']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(str_columns := example_correct_table.select(cs.string()).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5224c641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lat', 'Lon']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(float_columns := example_correct_table.select(cs.float()).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4ef89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date/Time': String, 'Base': String, 'Lat': Float64, 'Lon': Float64}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(col_and_types := {c: pl.String() for c in str_columns\n",
    "                  } |    # Merge operator\n",
    "                  {c:pl.Float64() for c in float_columns\n",
    "                  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "009648a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (700_000, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date/Time</th><th>Base</th><th>Lat</th><th>Lon</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;6/19/2014 16:49:00&quot;</td><td>&quot;B02682&quot;</td><td>40.7568</td><td>-73.9701</td></tr><tr><td>&quot;6/12/2014 21:25:00&quot;</td><td>&quot;B02598&quot;</td><td>40.6463</td><td>-73.7768</td></tr><tr><td>&quot;6/15/2014 22:23:00&quot;</td><td>&quot;B02512&quot;</td><td>40.7205</td><td>-73.9575</td></tr><tr><td>&quot;6/14/2014 20:34:00&quot;</td><td>&quot;B02617&quot;</td><td>40.7639</td><td>-73.9624</td></tr><tr><td>&quot;6/13/2014 14:36:00&quot;</td><td>&quot;B02598&quot;</td><td>40.7665</td><td>-73.9667</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;7/9/2014 7:17:00&quot;</td><td>&quot;B02617&quot;</td><td>40.7329</td><td>-73.9794</td></tr><tr><td>&quot;7/24/2014 13:34:00&quot;</td><td>&quot;B02682&quot;</td><td>40.6713</td><td>-73.9846</td></tr><tr><td>&quot;7/3/2014 10:06:00&quot;</td><td>&quot;B02598&quot;</td><td>40.7623</td><td>-73.966</td></tr><tr><td>&quot;7/8/2014 22:21:00&quot;</td><td>&quot;B02617&quot;</td><td>40.767</td><td>-73.9171</td></tr><tr><td>&quot;7/14/2014 17:01:00&quot;</td><td>&quot;B02682&quot;</td><td>40.7331</td><td>-73.9948</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (700_000, 4)\n",
       "┌────────────────────┬────────┬─────────┬──────────┐\n",
       "│ Date/Time          ┆ Base   ┆ Lat     ┆ Lon      │\n",
       "│ ---                ┆ ---    ┆ ---     ┆ ---      │\n",
       "│ str                ┆ str    ┆ f64     ┆ f64      │\n",
       "╞════════════════════╪════════╪═════════╪══════════╡\n",
       "│ 6/19/2014 16:49:00 ┆ B02682 ┆ 40.7568 ┆ -73.9701 │\n",
       "│ 6/12/2014 21:25:00 ┆ B02598 ┆ 40.6463 ┆ -73.7768 │\n",
       "│ 6/15/2014 22:23:00 ┆ B02512 ┆ 40.7205 ┆ -73.9575 │\n",
       "│ 6/14/2014 20:34:00 ┆ B02617 ┆ 40.7639 ┆ -73.9624 │\n",
       "│ 6/13/2014 14:36:00 ┆ B02598 ┆ 40.7665 ┆ -73.9667 │\n",
       "│ …                  ┆ …      ┆ …       ┆ …        │\n",
       "│ 7/9/2014 7:17:00   ┆ B02617 ┆ 40.7329 ┆ -73.9794 │\n",
       "│ 7/24/2014 13:34:00 ┆ B02682 ┆ 40.6713 ┆ -73.9846 │\n",
       "│ 7/3/2014 10:06:00  ┆ B02598 ┆ 40.7623 ┆ -73.966  │\n",
       "│ 7/8/2014 22:21:00  ┆ B02617 ┆ 40.767  ┆ -73.9171 │\n",
       "│ 7/14/2014 17:01:00 ┆ B02682 ┆ 40.7331 ┆ -73.9948 │\n",
       "└────────────────────┴────────┴─────────┴──────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_combined :=\n",
    " pl.concat([pl.read_csv(p)\n",
    "              .rename(col_rename)\n",
    "              .select([pl.col(c).cast(t) for c, t in col_and_types.items()])     # Reorder, remove, or recast columns as needed.\n",
    "            for p, col_rename in fixed_columns.items()\n",
    "           ]\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4c9a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the bad file (See below)\n",
    "!rm ./data/uber/uber-bad.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e119d",
   "metadata": {},
   "source": [
    "## <font color = \"red\"> Exercise 4.3 </font>\n",
    "\n",
    "### Task: Explore the column names in the City Bike data files\n",
    "\n",
    "The data folder contains a set of City Bike data files. Explore the column names in these files to find and fix any problems.  Provide a summary of the problems you found and how you fixed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61216440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/7ykd2jqx0_bb8s6ybyq242480000gn/T/ipykernel_22799/1840245184.py:14: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.\n",
      "  .pivot(index = 'Column', columns='file', values='ones')\n",
      "/var/folders/1p/7ykd2jqx0_bb8s6ybyq242480000gn/T/ipykernel_22799/1840245184.py:19: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  join_next_citi = lambda df1, df2: (df1.join(df2,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (255_063, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Start Time</th><th>Stop Time</th><th>Start Station Name</th><th>End Station Name</th><th>User Type</th><th>Start Station Latitude</th><th>Start Station Longitude</th><th>End Station Latitude</th><th>End Station Longitude</th><th>Trip Duration</th><th>Start Station Id</th><th>End Station Id</th><th>Bike Id</th><th>Birth Year</th><th>Gender</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2016-01-01 00:02:52&quot;</td><td>&quot;2016-01-01 00:08:54&quot;</td><td>&quot;Grove St PATH&quot;</td><td>&quot;Brunswick St&quot;</td><td>&quot;Subscriber&quot;</td><td>40.719586</td><td>-74.043117</td><td>40.724176</td><td>-74.050656</td><td>362</td><td>3186</td><td>3209</td><td>24647</td><td>1964</td><td>2</td></tr><tr><td>&quot;2016-01-01 00:18:22&quot;</td><td>&quot;2016-01-01 00:21:42&quot;</td><td>&quot;Grove St PATH&quot;</td><td>&quot;Van Vorst Park&quot;</td><td>&quot;Subscriber&quot;</td><td>40.719586</td><td>-74.043117</td><td>40.718489</td><td>-74.047727</td><td>200</td><td>3186</td><td>3213</td><td>24605</td><td>1962</td><td>1</td></tr><tr><td>&quot;2016-01-01 00:18:25&quot;</td><td>&quot;2016-01-01 00:21:47&quot;</td><td>&quot;Grove St PATH&quot;</td><td>&quot;Van Vorst Park&quot;</td><td>&quot;Subscriber&quot;</td><td>40.719586</td><td>-74.043117</td><td>40.718489</td><td>-74.047727</td><td>202</td><td>3186</td><td>3213</td><td>24689</td><td>1962</td><td>2</td></tr><tr><td>&quot;2016-01-01 00:23:13&quot;</td><td>&quot;2016-01-01 00:27:21&quot;</td><td>&quot;Brunswick St&quot;</td><td>&quot;Hamilton Park&quot;</td><td>&quot;Subscriber&quot;</td><td>40.724176</td><td>-74.050656</td><td>40.727596</td><td>-74.044247</td><td>248</td><td>3209</td><td>3203</td><td>24693</td><td>1984</td><td>1</td></tr><tr><td>&quot;2016-01-01 01:03:20&quot;</td><td>&quot;2016-01-01 01:18:24&quot;</td><td>&quot;Sip Ave&quot;</td><td>&quot;Pershing Field&quot;</td><td>&quot;Customer&quot;</td><td>40.730743</td><td>-74.063784</td><td>40.742677</td><td>-74.051789</td><td>903</td><td>3195</td><td>3210</td><td>24573</td><td>null</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2016-01-31 23:09:36&quot;</td><td>&quot;2016-01-31 23:21:42&quot;</td><td>&quot;Pershing Field&quot;</td><td>&quot;Van Vorst Park&quot;</td><td>&quot;Subscriber&quot;</td><td>40.742677</td><td>-74.051789</td><td>40.718489</td><td>-74.047727</td><td>726</td><td>3210</td><td>3213</td><td>24669</td><td>1965</td><td>1</td></tr><tr><td>&quot;2016-01-31 23:17:17&quot;</td><td>&quot;2016-01-31 23:21:34&quot;</td><td>&quot;MLK Light Rail&quot;</td><td>&quot;Garfield Ave Station&quot;</td><td>&quot;Subscriber&quot;</td><td>40.711131</td><td>-74.078885</td><td>40.710467</td><td>-74.070039</td><td>257</td><td>3200</td><td>3190</td><td>24718</td><td>1987</td><td>1</td></tr><tr><td>&quot;2016-01-31 23:38:33&quot;</td><td>&quot;2016-01-31 23:47:39&quot;</td><td>&quot;Essex Light Rail&quot;</td><td>&quot;Newport PATH&quot;</td><td>&quot;Subscriber&quot;</td><td>40.712774</td><td>-74.036486</td><td>40.727224</td><td>-74.033759</td><td>545</td><td>3214</td><td>3202</td><td>24619</td><td>1972</td><td>1</td></tr><tr><td>&quot;2016-01-31 23:45:10&quot;</td><td>&quot;2016-01-31 23:49:42&quot;</td><td>&quot;Grove St PATH&quot;</td><td>&quot;Hamilton Park&quot;</td><td>&quot;Subscriber&quot;</td><td>40.719586</td><td>-74.043117</td><td>40.727596</td><td>-74.044247</td><td>271</td><td>3186</td><td>3203</td><td>24537</td><td>1984</td><td>1</td></tr><tr><td>&quot;2016-01-31 23:55:36&quot;</td><td>&quot;2016-02-01 00:19:10&quot;</td><td>&quot;Liberty Light Rail&quot;</td><td>&quot;Newport Pkwy&quot;</td><td>&quot;Subscriber&quot;</td><td>40.711242</td><td>-74.055701</td><td>40.728745</td><td>-74.032108</td><td>1413</td><td>3192</td><td>3199</td><td>24671</td><td>1977</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (255_063, 15)\n",
       "┌─────────────┬─────────────┬─────────────┬────────────┬───┬────────────┬─────────┬───────┬────────┐\n",
       "│ Start Time  ┆ Stop Time   ┆ Start       ┆ End        ┆ … ┆ End        ┆ Bike Id ┆ Birth ┆ Gender │\n",
       "│ ---         ┆ ---         ┆ Station     ┆ Station    ┆   ┆ Station Id ┆ ---     ┆ Year  ┆ ---    │\n",
       "│ str         ┆ str         ┆ Name        ┆ Name       ┆   ┆ ---        ┆ i64     ┆ ---   ┆ i64    │\n",
       "│             ┆             ┆ ---         ┆ ---        ┆   ┆ i64        ┆         ┆ i64   ┆        │\n",
       "│             ┆             ┆ str         ┆ str        ┆   ┆            ┆         ┆       ┆        │\n",
       "╞═════════════╪═════════════╪═════════════╪════════════╪═══╪════════════╪═════════╪═══════╪════════╡\n",
       "│ 2016-01-01  ┆ 2016-01-01  ┆ Grove St    ┆ Brunswick  ┆ … ┆ 3209       ┆ 24647   ┆ 1964  ┆ 2      │\n",
       "│ 00:02:52    ┆ 00:08:54    ┆ PATH        ┆ St         ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-01  ┆ 2016-01-01  ┆ Grove St    ┆ Van Vorst  ┆ … ┆ 3213       ┆ 24605   ┆ 1962  ┆ 1      │\n",
       "│ 00:18:22    ┆ 00:21:42    ┆ PATH        ┆ Park       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-01  ┆ 2016-01-01  ┆ Grove St    ┆ Van Vorst  ┆ … ┆ 3213       ┆ 24689   ┆ 1962  ┆ 2      │\n",
       "│ 00:18:25    ┆ 00:21:47    ┆ PATH        ┆ Park       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-01  ┆ 2016-01-01  ┆ Brunswick   ┆ Hamilton   ┆ … ┆ 3203       ┆ 24693   ┆ 1984  ┆ 1      │\n",
       "│ 00:23:13    ┆ 00:27:21    ┆ St          ┆ Park       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-01  ┆ 2016-01-01  ┆ Sip Ave     ┆ Pershing   ┆ … ┆ 3210       ┆ 24573   ┆ null  ┆ 0      │\n",
       "│ 01:03:20    ┆ 01:18:24    ┆             ┆ Field      ┆   ┆            ┆         ┆       ┆        │\n",
       "│ …           ┆ …           ┆ …           ┆ …          ┆ … ┆ …          ┆ …       ┆ …     ┆ …      │\n",
       "│ 2016-01-31  ┆ 2016-01-31  ┆ Pershing    ┆ Van Vorst  ┆ … ┆ 3213       ┆ 24669   ┆ 1965  ┆ 1      │\n",
       "│ 23:09:36    ┆ 23:21:42    ┆ Field       ┆ Park       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-31  ┆ 2016-01-31  ┆ MLK Light   ┆ Garfield   ┆ … ┆ 3190       ┆ 24718   ┆ 1987  ┆ 1      │\n",
       "│ 23:17:17    ┆ 23:21:34    ┆ Rail        ┆ Ave        ┆   ┆            ┆         ┆       ┆        │\n",
       "│             ┆             ┆             ┆ Station    ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-31  ┆ 2016-01-31  ┆ Essex Light ┆ Newport    ┆ … ┆ 3202       ┆ 24619   ┆ 1972  ┆ 1      │\n",
       "│ 23:38:33    ┆ 23:47:39    ┆ Rail        ┆ PATH       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-31  ┆ 2016-01-31  ┆ Grove St    ┆ Hamilton   ┆ … ┆ 3203       ┆ 24537   ┆ 1984  ┆ 1      │\n",
       "│ 23:45:10    ┆ 23:49:42    ┆ PATH        ┆ Park       ┆   ┆            ┆         ┆       ┆        │\n",
       "│ 2016-01-31  ┆ 2016-02-01  ┆ Liberty     ┆ Newport    ┆ … ┆ 3199       ┆ 24671   ┆ 1977  ┆ 2      │\n",
       "│ 23:55:36    ┆ 00:19:10    ┆ Light Rail  ┆ Pkwy       ┆   ┆            ┆         ┆       ┆        │\n",
       "└─────────────┴─────────────┴─────────────┴────────────┴───┴────────────┴─────────┴───────┴────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "(citi_paths :=\n",
    " glob('./data/city_bike/*.csv')\n",
    ")\n",
    "\n",
    "(citi_tables :=\n",
    " [pl.read_csv(p)\n",
    "    .head(1)\n",
    "     .with_columns(file = pl.lit(p.replace('\\\\','/').split('/')[-1]))\n",
    "     .unpivot(index='file', variable_name='Column')\n",
    "     .drop('value')\n",
    "     .with_columns(pl.lit(1).alias('ones'))\n",
    "     .pivot(index = 'Column', columns='file', values='ones')\n",
    "  for p in citi_paths\n",
    "  ]\n",
    ")\n",
    "\n",
    "join_next_citi = lambda df1, df2: (df1.join(df2, \n",
    "                                       on='Column', \n",
    "                                       how = 'outer', \n",
    "                                       suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "(combined_tables_citi :=\n",
    " reduce(join_next_citi, citi_tables)\n",
    " .fill_null(0)\n",
    " .sort('Column')\n",
    ")\n",
    "\n",
    "(combined_tables_citi :=\n",
    " combined_tables_citi\n",
    " .with_columns(all = pl.reduce(mul, cs.starts_with('JC')),\n",
    "               count = pl.reduce(add, cs.starts_with('JC')),\n",
    "               )\n",
    ")\n",
    "\n",
    "join_next_citi = lambda df1, df2: (df1.join(df2, on='Column', how = 'full', suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "\n",
    "(citi_column_summary :=\n",
    " pipe(glob('./data/city_bike/*.csv'),\n",
    "     lambda L: [pl.read_csv(p)\n",
    "                  .with_columns(file = pl.lit(p.replace('\\\\','/').split('/')[-1]))\n",
    "                  .head(1) \n",
    "                  .unpivot(index='file', \n",
    "                           variable_name='Column')\n",
    "                  .drop('value')\n",
    "                  .with_columns(pl.lit(1).alias('ones'))\n",
    "                  .pivot(index = 'Column', \n",
    "                         on='file', \n",
    "                         values='ones') \n",
    "                for p in L \n",
    "                ],\n",
    "     lambda L: reduce(join_next_citi, L).sort('Column').fill_null(0),\n",
    "     lambda df: df.with_columns(all = pl.reduce(mul, cs.starts_with('JC')), \n",
    "                                count = pl.reduce(add, cs.starts_with('JC'))\n",
    "                               ),\n",
    "     )\n",
    ")\n",
    "\n",
    "(citi_column_summary\n",
    " .filter(pl.col('all') == 0)\n",
    ")\n",
    "\n",
    "(citi_column_summary\n",
    " .filter(pl.col('count') != pl.col('count').max())\n",
    ")\n",
    "\n",
    "f = citi_paths[0] \n",
    "original_columns_citi = (pl.read_csv(f).head(1).columns)\n",
    "\n",
    "(pl.read_csv(f)\n",
    "   .rename({c:c.upper() for c in original_columns_citi})\n",
    "   .write_csv(f'data/city_bike/citi-bad.csv')\n",
    ")\n",
    "\n",
    "join_next_citi = lambda df1, df2: (df1.join(df2, on='Column', how = 'full', suffix = '_right')\n",
    "                                 .with_columns(Column = pl.coalesce('Column', 'Column_right'))\n",
    "                                 .drop('Column_right')\n",
    "                             )\n",
    "\n",
    "\n",
    "(citi_column_summary :=\n",
    " pipe(glob('./data/city_bike/*.csv'),\n",
    "     lambda L: [pl.read_csv(p)\n",
    "                  .with_columns(file = pl.lit(p.split('/')[-1]))\n",
    "                  .head(1) \n",
    "                  .unpivot(index='file', \n",
    "                           variable_name='Column')\n",
    "                  .drop('value')\n",
    "                  .with_columns(pl.lit(1).alias('ones'))\n",
    "                  .pivot(index = 'Column', \n",
    "                         on='file', \n",
    "                         values='ones') \n",
    "                for p in L \n",
    "                ],\n",
    "     lambda L: reduce(join_next_citi, L).sort('Column').fill_null(0),\n",
    "     lambda df: df.with_columns(all = pl.reduce(mul, cs.starts_with('JC')), \n",
    "                                count = pl.reduce(add, cs.starts_with('JC'))\n",
    "                               ),\n",
    "     )\n",
    ")\n",
    "\n",
    "(citi_column_summary\n",
    " .filter(pl.col('all') == 0)\n",
    ")\n",
    "\n",
    "(citi_column_summary\n",
    " .filter(pl.col('count') != pl.col('count').max())\n",
    ")\n",
    "\n",
    "(citi_paths :=\n",
    " glob('./data/city_bike/*.csv')\n",
    ")\n",
    "\n",
    "(original_columns_citi :=\n",
    " {p:{col: col\n",
    "     for col in \n",
    "     pl.read_csv(p).columns\n",
    "    }\n",
    "  for p in citi_paths\n",
    " }\n",
    "\n",
    ")\n",
    "\n",
    "(fixed_columns_citi :=\n",
    " {**original_columns_citi, \n",
    "  './data/city_bike/citi-bad.csv':{col:col.title() \n",
    "                             for col in original_columns_citi['./data/city_bike/citi-bad.csv']\n",
    "                             },\n",
    "}\n",
    ")\n",
    "\n",
    "(col_and_types_citi := {'Trip Duration': pl.String(),\n",
    "                   'Start Time': pl.Float64(),\n",
    "                   'Stop Time': pl.Float64(),\n",
    "                   'Start Station Id': pl.String(),\n",
    "                   'Start Station Name': pl.String(),\n",
    "                   'Start Station Latitude': pl.Float64(),\n",
    "                   'Start Station Longitude': pl.Float64(),\n",
    "                   'End Station ID': pl.Int64(),\n",
    "                   'End Station Name': pl.String(),\n",
    "                   'End Station Latitude': pl.Float64(),\n",
    "                   'End Station Longitude': pl.Float64(),\n",
    "                   'Bike ID': pl.Int64(),\n",
    "                   'User Type': pl.String(),\n",
    "                   'Birth Year': pl.Int64(),\n",
    "                   'Gender': pl.String(),\n",
    "                  }\n",
    ")\n",
    "\n",
    "(example_correct_table_citi :=\n",
    "    pl.read_csv(citi_paths[0])\n",
    "    .rename({c: c.title() for c in pl.read_csv(citi_paths[0]).columns})\n",
    "    .head()\n",
    ")\n",
    "\n",
    "\n",
    "(str_columns_citi := example_correct_table_citi.select(cs.string()).columns\n",
    ")\n",
    "\n",
    "(float_columns_citi := example_correct_table_citi.select(cs.float()).columns\n",
    ")\n",
    "\n",
    "(integer_columns_citi := example_correct_table_citi.select(cs.integer()).columns\n",
    ")\n",
    "\n",
    "(col_and_types_citi := {c: pl.String() for c in str_columns_citi\n",
    "                  } |    # Merge operator\n",
    "                  {c:pl.Float64() for c in float_columns_citi\n",
    "                  } |    # Merge operator\n",
    "                  {c:pl.Int64() for c in integer_columns_citi\n",
    "                  }\n",
    ")\n",
    "\n",
    "(citi_combined :=\n",
    " pl.concat([\n",
    "     pl.read_csv(p)\n",
    "       .rename({c: c.title() for c in pl.read_csv(p).columns})\n",
    "       .select([pl.col(c).cast(t) for c, t in col_and_types_citi.items()])\n",
    "     for p in citi_paths\n",
    " ])\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28414951",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Your findings here.<font>\n",
    "    One issue was the names of the columns are different in each csv file. The way to fix this is is to rename them so all the capitilizations are the exact same for the colummn headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec623499-e7c8-423a-8a0d-f7d996a04c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
